MODEL=ollama/llama3.2
API_BASE=http://ollama:11434

# LLaMA3.2 – 3B/2GB 
# Ideal para: Análise de texto leve localmente
# Adequação: Bom custo/desempenho para currículos simples
# Limitações: Sem suporte a imagem, raciocínio limitado

# Qwen2.5 – 7B/4,7GB
# Ideal para: Currículos com texto e imagem (multimodal)
# Adequação: Boa cobertura linguística; versão multimodal disponível
# Limitações: Multimodal mais pesado; foca em chinês/inglês

# OpenHermes – 7B/4,1GB
# Ideal para: Extração semântica e instruções em texto
# Adequação: Excelente para currículos textuais complexos
# Limitações: Sem suporte a imagens ou PDFs visuais

# DeepSeek-R1 – 7B/4,7GB
# Ideal para: Texto + elementos visuais (multimodal)
# Adequação: Robusto para currículos híbridos
# Limitações: Alto uso de recursos; precisa GPU dedicada

# Apagar os modelos do conteiner do Ollama (se necessário).
# docker exec -it ollama /bin/bash
# rm -rf ~/.ollama/models/blobs/*